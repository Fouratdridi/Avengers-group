{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 19:58:29,857 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "2023-03-22 19:58:58,992 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-03-22T19:58:58.976957', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "gmodel = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0123291 ,  0.20410156, -0.28515625,  0.21679688,  0.11816406,\n",
       "        0.08300781,  0.04980469, -0.00952148,  0.22070312, -0.12597656,\n",
       "        0.08056641, -0.5859375 , -0.00445557, -0.296875  , -0.01312256,\n",
       "       -0.08349609,  0.05053711,  0.15136719, -0.44921875, -0.0135498 ,\n",
       "        0.21484375, -0.14746094,  0.22460938, -0.125     , -0.09716797,\n",
       "        0.24902344, -0.2890625 ,  0.36523438,  0.41210938, -0.0859375 ,\n",
       "       -0.07861328, -0.19726562, -0.09082031, -0.14160156, -0.10253906,\n",
       "        0.13085938, -0.00346375,  0.07226562,  0.04418945,  0.34570312,\n",
       "        0.07470703, -0.11230469,  0.06738281,  0.11230469,  0.01977539,\n",
       "       -0.12353516,  0.20996094, -0.07226562, -0.02783203,  0.05541992,\n",
       "       -0.33398438,  0.08544922,  0.34375   ,  0.13964844,  0.04931641,\n",
       "       -0.13476562,  0.16308594, -0.37304688,  0.39648438,  0.10693359,\n",
       "        0.22167969,  0.21289062, -0.08984375,  0.20703125,  0.08935547,\n",
       "       -0.08251953,  0.05957031,  0.10205078, -0.19238281, -0.09082031,\n",
       "        0.4921875 ,  0.03955078, -0.07080078, -0.0019989 , -0.23046875,\n",
       "        0.25585938,  0.08984375, -0.10644531,  0.00105286, -0.05883789,\n",
       "        0.05102539, -0.0291748 ,  0.19335938, -0.14160156, -0.33398438,\n",
       "        0.08154297, -0.27539062,  0.10058594, -0.10449219, -0.12353516,\n",
       "       -0.140625  ,  0.03491211, -0.11767578, -0.1796875 , -0.21484375,\n",
       "       -0.23828125,  0.08447266, -0.07519531, -0.25976562, -0.21289062,\n",
       "       -0.22363281, -0.09716797,  0.11572266,  0.15429688,  0.07373047,\n",
       "       -0.27539062,  0.14257812, -0.0201416 ,  0.10009766, -0.19042969,\n",
       "       -0.09375   ,  0.14160156,  0.17089844,  0.3125    , -0.16699219,\n",
       "       -0.08691406, -0.05004883, -0.24902344, -0.20800781, -0.09423828,\n",
       "       -0.12255859, -0.09472656, -0.390625  , -0.06640625, -0.31640625,\n",
       "        0.10986328, -0.00156403,  0.04345703,  0.15625   , -0.18945312,\n",
       "       -0.03491211,  0.03393555, -0.14453125,  0.01611328, -0.14160156,\n",
       "       -0.02392578,  0.01501465,  0.07568359,  0.10742188,  0.12695312,\n",
       "        0.10693359, -0.01184082, -0.24023438,  0.0291748 ,  0.16210938,\n",
       "        0.19921875, -0.28125   ,  0.16699219, -0.11621094, -0.25585938,\n",
       "        0.38671875, -0.06640625, -0.4609375 , -0.06176758, -0.14453125,\n",
       "       -0.11621094,  0.05688477,  0.03588867, -0.10693359,  0.18847656,\n",
       "       -0.16699219, -0.01794434,  0.10986328, -0.12353516, -0.16308594,\n",
       "       -0.14453125,  0.12890625,  0.11523438,  0.13671875,  0.05688477,\n",
       "       -0.08105469, -0.06152344, -0.06689453,  0.27929688, -0.19628906,\n",
       "        0.07226562,  0.12304688, -0.20996094, -0.22070312,  0.21386719,\n",
       "       -0.1484375 , -0.05932617,  0.05224609,  0.06445312, -0.02636719,\n",
       "        0.13183594,  0.19433594,  0.27148438,  0.18652344,  0.140625  ,\n",
       "        0.06542969, -0.14453125,  0.05029297,  0.08837891,  0.12255859,\n",
       "        0.26757812,  0.0534668 , -0.32226562, -0.20703125,  0.18164062,\n",
       "        0.04418945, -0.22167969, -0.13769531, -0.04174805, -0.00286865,\n",
       "        0.04077148,  0.07275391, -0.08300781,  0.08398438, -0.3359375 ,\n",
       "       -0.40039062,  0.01757812, -0.18652344, -0.0480957 , -0.19140625,\n",
       "        0.10107422,  0.09277344, -0.30664062, -0.19921875, -0.0168457 ,\n",
       "        0.12207031,  0.14648438, -0.12890625, -0.23535156, -0.05371094,\n",
       "       -0.06640625,  0.06884766, -0.03637695,  0.2109375 , -0.06005859,\n",
       "        0.19335938,  0.05151367, -0.05322266,  0.02893066, -0.27539062,\n",
       "        0.08447266,  0.328125  ,  0.01818848,  0.01495361,  0.04711914,\n",
       "        0.37695312, -0.21875   , -0.03393555,  0.01116943,  0.36914062,\n",
       "        0.02160645,  0.03466797,  0.07275391,  0.16015625, -0.16503906,\n",
       "       -0.296875  ,  0.15039062, -0.29101562,  0.13964844,  0.00448608,\n",
       "        0.171875  , -0.21972656,  0.09326172, -0.19042969,  0.01599121,\n",
       "       -0.09228516,  0.15722656, -0.14160156, -0.0534668 ,  0.03613281,\n",
       "        0.23632812, -0.15136719, -0.00689697, -0.27148438, -0.07128906,\n",
       "       -0.16503906,  0.18457031, -0.08398438,  0.18554688,  0.11669922,\n",
       "        0.02758789, -0.04760742,  0.17871094,  0.06542969, -0.03540039,\n",
       "        0.22949219,  0.02697754, -0.09765625,  0.26953125,  0.08349609,\n",
       "       -0.13085938, -0.10107422, -0.00738525,  0.07128906,  0.14941406,\n",
       "       -0.20605469,  0.18066406, -0.15820312,  0.05932617,  0.28710938,\n",
       "       -0.04663086,  0.15136719,  0.4921875 , -0.27539062,  0.05615234],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.12695312e-02, -2.23388672e-02, -1.72851562e-01,  1.61132812e-01,\n",
       "       -8.44726562e-02,  5.73730469e-02,  5.85937500e-02, -8.25195312e-02,\n",
       "       -1.53808594e-02, -6.34765625e-02,  1.79687500e-01, -4.23828125e-01,\n",
       "       -2.25830078e-02, -1.66015625e-01, -2.51464844e-02,  1.07421875e-01,\n",
       "       -1.99218750e-01,  1.59179688e-01, -1.87500000e-01, -1.20117188e-01,\n",
       "        1.55273438e-01, -9.91210938e-02,  1.42578125e-01, -1.64062500e-01,\n",
       "       -8.93554688e-02,  2.00195312e-01, -1.49414062e-01,  3.20312500e-01,\n",
       "        3.28125000e-01,  2.44140625e-02, -9.71679688e-02, -8.20312500e-02,\n",
       "       -3.63769531e-02, -8.59375000e-02, -9.86328125e-02,  7.78198242e-03,\n",
       "       -1.34277344e-02,  5.27343750e-02,  1.48437500e-01,  3.33984375e-01,\n",
       "        1.66015625e-02, -2.12890625e-01, -1.50756836e-02,  5.24902344e-02,\n",
       "       -1.07421875e-01, -8.88671875e-02,  2.49023438e-01, -7.03125000e-02,\n",
       "       -1.59912109e-02,  7.56835938e-02, -7.03125000e-02,  1.19140625e-01,\n",
       "        2.29492188e-01,  1.41601562e-02,  1.15234375e-01,  7.50732422e-03,\n",
       "        2.75390625e-01, -2.44140625e-01,  2.96875000e-01,  3.49121094e-02,\n",
       "        2.42187500e-01,  1.35742188e-01,  1.42578125e-01,  1.75781250e-02,\n",
       "        2.92968750e-02, -1.21582031e-01,  2.28271484e-02, -4.76074219e-02,\n",
       "       -1.55273438e-01,  3.14331055e-03,  3.45703125e-01,  1.22558594e-01,\n",
       "       -1.95312500e-01,  8.10546875e-02, -6.83593750e-02, -1.47094727e-02,\n",
       "        2.14843750e-01, -1.21093750e-01,  1.57226562e-01, -2.07031250e-01,\n",
       "        1.36718750e-01, -1.29882812e-01,  5.29785156e-02, -2.71484375e-01,\n",
       "       -2.98828125e-01, -1.84570312e-01, -2.29492188e-01,  1.19140625e-01,\n",
       "        1.53198242e-02, -2.61718750e-01, -1.23046875e-01, -1.86767578e-02,\n",
       "       -6.49414062e-02, -8.15429688e-02,  7.86132812e-02, -3.53515625e-01,\n",
       "        5.24902344e-02, -2.45361328e-02, -5.43212891e-03, -2.08984375e-01,\n",
       "       -2.10937500e-01, -1.79687500e-01,  2.42187500e-01,  2.57812500e-01,\n",
       "        1.37695312e-01, -2.10937500e-01, -2.17285156e-02, -1.38671875e-01,\n",
       "        1.84326172e-02, -1.23901367e-02, -1.59179688e-01,  1.61132812e-01,\n",
       "        2.08007812e-01,  1.03027344e-01,  9.81445312e-02, -6.83593750e-02,\n",
       "       -8.72802734e-03, -2.89062500e-01, -2.14843750e-01, -1.14257812e-01,\n",
       "       -2.21679688e-01,  4.12597656e-02, -3.12500000e-01, -5.59082031e-02,\n",
       "       -9.76562500e-02,  5.81054688e-02, -4.05273438e-02, -1.73828125e-01,\n",
       "        1.64062500e-01, -2.53906250e-01, -1.54296875e-01, -2.31933594e-02,\n",
       "       -2.38281250e-01,  2.07519531e-02, -2.73437500e-01,  3.90625000e-03,\n",
       "        1.13769531e-01, -1.73828125e-01,  2.57812500e-01,  2.35351562e-01,\n",
       "        5.22460938e-02,  6.83593750e-02, -1.75781250e-01,  1.60156250e-01,\n",
       "       -5.98907471e-04,  5.98144531e-02, -2.11914062e-01, -5.54199219e-02,\n",
       "       -7.51953125e-02, -3.06640625e-01,  4.27734375e-01,  5.32226562e-02,\n",
       "       -2.08984375e-01, -5.71289062e-02, -2.09960938e-01,  3.29589844e-02,\n",
       "        1.05468750e-01, -1.50390625e-01, -9.37500000e-02,  1.16699219e-01,\n",
       "        6.44531250e-02,  2.80761719e-02,  2.41210938e-01, -1.25976562e-01,\n",
       "       -1.00585938e-01, -1.22680664e-02, -3.26156616e-04,  1.58691406e-02,\n",
       "        1.27929688e-01, -3.32031250e-02,  4.07714844e-02, -1.31835938e-01,\n",
       "        9.81445312e-02,  1.74804688e-01, -2.36328125e-01,  5.17578125e-02,\n",
       "        1.83593750e-01,  2.42919922e-02, -4.31640625e-01,  2.46093750e-01,\n",
       "       -3.03955078e-02, -2.47802734e-02, -1.17187500e-01,  1.61132812e-01,\n",
       "       -5.71289062e-02,  1.16577148e-02,  2.81250000e-01,  4.27734375e-01,\n",
       "        4.56542969e-02,  1.01074219e-01, -3.95507812e-02,  1.77001953e-02,\n",
       "       -8.98437500e-02,  1.35742188e-01,  2.08007812e-01,  1.88476562e-01,\n",
       "       -1.52343750e-01, -2.37304688e-01, -1.90429688e-01,  7.12890625e-02,\n",
       "       -2.46093750e-01, -2.61718750e-01, -2.34375000e-01, -1.45507812e-01,\n",
       "       -1.17187500e-02, -1.50390625e-01, -1.13281250e-01,  1.82617188e-01,\n",
       "        2.63671875e-01, -1.37695312e-01, -4.58984375e-01, -4.68750000e-02,\n",
       "       -1.26953125e-01, -4.22363281e-02, -1.66992188e-01,  1.26953125e-01,\n",
       "        2.59765625e-01, -2.44140625e-01, -2.19726562e-01, -8.69140625e-02,\n",
       "        1.59179688e-01, -3.78417969e-02,  8.97216797e-03, -2.77343750e-01,\n",
       "       -1.04980469e-01, -1.75781250e-01,  2.28515625e-01, -2.70996094e-02,\n",
       "        2.85156250e-01, -2.73437500e-01,  1.61132812e-02,  5.90820312e-02,\n",
       "       -2.39257812e-01,  1.77734375e-01, -1.34765625e-01,  1.38671875e-01,\n",
       "        3.53515625e-01,  1.22070312e-01,  1.43554688e-01,  9.22851562e-02,\n",
       "        2.29492188e-01, -3.00781250e-01, -4.88281250e-02, -1.79687500e-01,\n",
       "        2.96875000e-01,  1.75781250e-01,  4.80957031e-02, -3.38745117e-03,\n",
       "        7.91015625e-02, -2.38281250e-01, -2.31445312e-01,  1.66015625e-01,\n",
       "       -2.13867188e-01, -7.03125000e-02, -7.56835938e-02,  1.96289062e-01,\n",
       "       -1.29882812e-01, -1.05957031e-01, -3.53515625e-01, -1.16699219e-01,\n",
       "       -5.10253906e-02,  3.39355469e-02, -1.43554688e-01, -3.90625000e-03,\n",
       "        1.73828125e-01, -9.96093750e-02, -1.66015625e-01, -8.54492188e-02,\n",
       "       -3.82812500e-01,  5.90820312e-02, -6.22558594e-02,  8.83789062e-02,\n",
       "       -8.88671875e-02,  3.28125000e-01,  6.83593750e-02, -1.91406250e-01,\n",
       "       -8.35418701e-04,  1.04003906e-01,  1.52343750e-01, -1.53350830e-03,\n",
       "        4.16015625e-01, -3.32031250e-02,  1.49414062e-01,  2.42187500e-01,\n",
       "       -1.76757812e-01, -4.93164062e-02, -1.24511719e-01,  1.25976562e-01,\n",
       "        1.74804688e-01,  2.81250000e-01, -1.80664062e-01,  1.03027344e-01,\n",
       "       -2.75390625e-01,  2.61718750e-01,  2.46093750e-01, -4.71191406e-02,\n",
       "        6.25000000e-02,  4.16015625e-01, -3.55468750e-01,  2.22656250e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19140625, -0.04296875,  0.27539062,  0.00488281, -0.3203125 ,\n",
       "        0.08203125,  0.05566406, -0.03613281, -0.31445312,  0.10693359,\n",
       "       -0.359375  ,  0.29882812,  0.02331543,  0.05517578, -0.140625  ,\n",
       "        0.1953125 , -0.23632812, -0.22167969, -0.06542969, -0.3359375 ,\n",
       "        0.25195312, -0.09326172,  0.54296875,  0.11328125, -0.28710938,\n",
       "       -0.12011719, -0.11181641,  0.20996094, -0.33203125,  0.30273438,\n",
       "       -0.3359375 , -0.12255859,  0.12890625, -0.28515625, -0.04223633,\n",
       "        0.25585938,  0.3203125 ,  0.07177734,  0.19042969, -0.01379395,\n",
       "        0.16992188, -0.22460938,  0.5078125 ,  0.08398438, -0.07519531,\n",
       "       -0.06396484,  0.05371094,  0.34570312,  0.46289062, -0.16699219,\n",
       "       -0.30664062,  0.15234375, -0.09765625, -0.26171875, -0.14160156,\n",
       "        0.2265625 ,  0.49609375, -0.10791016, -0.08447266,  0.234375  ,\n",
       "        0.04931641, -0.07128906,  0.05273438, -0.11914062,  0.09814453,\n",
       "        0.11181641, -0.13574219, -0.46875   ,  0.26171875,  0.12158203,\n",
       "        0.31445312,  0.05810547,  0.0703125 , -0.10107422, -0.27734375,\n",
       "       -0.16796875, -0.07128906, -0.08007812,  0.07226562, -0.1484375 ,\n",
       "        0.22949219,  0.03686523, -0.03857422,  0.00616455, -0.12255859,\n",
       "       -0.01940918, -0.0625    ,  0.26953125,  0.34179688, -0.00427246,\n",
       "       -0.49023438, -0.38867188, -0.24316406,  0.12304688,  0.07421875,\n",
       "       -0.25195312,  0.14941406, -0.265625  ,  0.30859375, -0.05834961,\n",
       "       -0.19726562, -0.14941406,  0.01031494, -0.07275391, -0.23632812,\n",
       "       -0.1484375 ,  0.3046875 , -0.10351562,  0.69140625, -0.29492188,\n",
       "       -0.25976562, -0.29296875,  0.31445312, -0.11083984, -0.5       ,\n",
       "       -0.04443359,  0.10058594,  0.04858398, -0.0625    ,  0.02001953,\n",
       "        0.08837891, -0.10058594, -0.00113678,  0.390625  ,  0.16894531,\n",
       "        0.01318359,  0.15625   ,  0.10595703,  0.29296875,  0.18457031,\n",
       "        0.13867188,  0.15820312, -0.38671875,  0.20214844,  0.17285156,\n",
       "        0.578125  , -0.05029297, -0.34179688,  0.46875   ,  0.34765625,\n",
       "        0.23535156, -0.20996094, -0.32226562, -0.26367188, -0.02160645,\n",
       "        0.50390625, -0.31054688, -0.2265625 ,  0.31640625, -0.14550781,\n",
       "        0.05639648, -0.18847656,  0.05126953,  0.73828125,  0.04174805,\n",
       "       -0.02392578, -0.375     , -0.18847656, -0.0625    ,  0.50390625,\n",
       "       -0.02844238, -0.05615234,  0.26367188, -0.0612793 ,  0.06030273,\n",
       "       -0.171875  , -0.00866699,  0.20019531, -0.03173828, -0.18164062,\n",
       "        0.40429688, -0.03710938, -0.03515625,  0.18261719, -0.47070312,\n",
       "       -0.07275391,  0.32617188, -0.17285156, -0.22265625,  0.27929688,\n",
       "       -0.57421875,  0.07275391,  0.20898438, -0.30273438,  0.19335938,\n",
       "        0.04907227, -0.15820312, -0.17675781,  0.18066406,  0.42773438,\n",
       "       -0.25390625,  0.29101562, -0.04760742, -0.28710938, -0.08837891,\n",
       "        0.28710938, -0.3828125 , -0.13574219,  0.05297852, -0.22265625,\n",
       "       -0.09179688, -0.06738281, -0.53125   ,  0.06933594,  0.02514648,\n",
       "        0.04443359, -0.18457031, -0.31054688,  0.02856445,  0.16992188,\n",
       "        0.01196289, -0.12109375,  0.00430298,  0.171875  ,  0.06640625,\n",
       "       -0.02954102, -0.39453125,  0.515625  ,  0.2109375 ,  0.03637695,\n",
       "       -0.390625  , -0.04980469, -0.13378906, -0.19140625, -0.34375   ,\n",
       "       -0.21289062,  0.375     ,  0.03039551,  0.1796875 , -0.37109375,\n",
       "        0.07763672, -0.07666016,  0.07910156, -0.15234375, -0.15429688,\n",
       "       -0.15039062,  0.12304688,  0.1796875 , -0.19335938,  0.125     ,\n",
       "        0.17285156,  0.03173828,  0.24121094, -0.34765625, -0.15136719,\n",
       "       -0.09619141,  0.09326172,  0.13964844, -0.20410156, -0.3671875 ,\n",
       "        0.02368164, -0.24804688,  0.17578125,  0.22460938,  0.18652344,\n",
       "       -0.44921875, -0.1640625 , -0.08837891,  0.1484375 , -0.0480957 ,\n",
       "        0.23144531, -0.06176758, -0.53125   , -0.23730469, -0.26953125,\n",
       "        0.02770996, -0.09667969, -0.05249023, -0.00543213, -0.05981445,\n",
       "        0.3203125 ,  0.34570312, -0.06591797, -0.05786133,  0.54296875,\n",
       "       -0.17675781, -0.05810547, -0.0378418 , -0.14550781, -0.265625  ,\n",
       "       -0.01153564,  0.3515625 ,  0.2421875 ,  0.24023438,  0.01025391,\n",
       "       -0.31445312, -0.20410156, -0.02172852, -0.21386719,  0.52734375,\n",
       "        0.12451172,  0.16113281, -0.46289062,  0.05126953, -0.02648926,\n",
       "       -0.546875  ,  0.30859375, -0.0534668 , -0.34765625,  0.3984375 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel['spatula']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609457"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.similarity('cat', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12412614"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.similarity('cat', 'spatula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'<[^>]+>', ' ', sent) # strip html tags\n",
    "    sent = re.sub(r'(\\w)\\'(\\w)', '\\1\\2', sent) # remove apostrophes\n",
    "    sent = re.sub(r'\\W', ' ', sent) # remove punctuation\n",
    "    sent = re.sub(r'\\s+', ' ', sent) # remove repeated spaces\n",
    "    sent = sent.strip()\n",
    "    return sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsupervised training data\n",
    "import re\n",
    "import os\n",
    "unsup_sentences = []\n",
    "\n",
    "# source: http://ai.stanford.edu/~amaas/data/sentiment/, data from IMDB\n",
    "for dirname in [\"train/pos\", \"train/neg\", \"train/unsup\", \"test/pos\", \"test/neg\"]:\n",
    "    for fname in sorted(os.listdir(f\"C:/Users/dridi/Downloads/aclImdb\")):\n",
    "        if fname[-4:] == '.txt':\n",
    "            with open(f\"C:/Users/dridi/Downloads/aclImdb\" + dirname + \"/\" + fname, encoding='UTF-8') as f:\n",
    "                sent = f.read()\n",
    "                words = extract_words(sent)\n",
    "                unsup_sentences.append(TaggedDocument(words, [dirname + \"/\" + fname]))\n",
    "\n",
    "# source: http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "for dirname in [\"review_polarity/txt_sentoken/pos\", \"review_polarity/txt_sentoken/neg\"]:\n",
    "    for fname in sorted(os.listdir(f\"C:/Users/dridi/Downloads/review_polarity\")):\n",
    "        if fname[-4:] == '.txt':\n",
    "            with open(f\"C:/Users/dridi/Downloads/review_polarity\" + dirname + \"/\" + fname, encoding='UTF-8') as f:\n",
    "                for i, sent in enumerate(f):\n",
    "                    words = extract_words(sent)\n",
    "                    unsup_sentences.append(TaggedDocument(words, [\"%s/%s-%d\" % (dirname, fname, i)]))\n",
    "                \n",
    "# source: https://nlp.stanford.edu/sentiment/, data from Rotten Tomatoes\n",
    "with open (f\"C:/Users/dridi/Downloads/stanfordSentimentTreebank/original_rt_snippets.txt\" , encoding='UTF-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        words = extract_words(line)\n",
    "        unsup_sentences.append(TaggedDocument(words, [\"rt-%d\" % i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unsup_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'centur', 'new', 'conan', 'and', 'that', 'h', 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', 'jean', 'claud', 'van', 'damme', 'or', 'steven', 'segal'], tags=['rt-0']),\n",
       " TaggedDocument(words=['the', 'gorgeously', 'elaborate', 'continuation', 'of', 'the', 'lord', 'of', 'the', 'rings', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'cannot', 'adequately', 'describe', 'co', 'writer', 'director', 'peter', 'jackso', 'expanded', 'vision', 'of', 'j', 'r', 'r', 'tolkie', 'middle', 'earth'], tags=['rt-1']),\n",
       " TaggedDocument(words=['effective', 'but', 'too', 'tepid', 'biopic'], tags=['rt-2']),\n",
       " TaggedDocument(words=['if', 'you', 'sometimes', 'like', 'to', 'go', 'to', 'the', 'movies', 'to', 'have', 'fun', 'wasabi', 'is', 'a', 'good', 'place', 'to', 'start'], tags=['rt-3']),\n",
       " TaggedDocument(words=['emerges', 'as', 'something', 'rare', 'an', 'issue', 'movie', 'tha', 'so', 'honest', 'and', 'keenly', 'observed', 'that', 'it', 'does', 'feel', 'like', 'one'], tags=['rt-4']),\n",
       " TaggedDocument(words=['the', 'film', 'provides', 'some', 'great', 'insight', 'into', 'the', 'neurotic', 'mindset', 'of', 'all', 'comics', 'even', 'those', 'who', 'have', 'reached', 'the', 'absolute', 'top', 'of', 'the', 'game'], tags=['rt-5']),\n",
       " TaggedDocument(words=['offers', 'that', 'rare', 'combination', 'of', 'entertainment', 'and', 'education'], tags=['rt-6']),\n",
       " TaggedDocument(words=['perhaps', 'no', 'picture', 'ever', 'made', 'has', 'more', 'literally', 'showed', 'that', 'the', 'road', 'to', 'hell', 'is', 'paved', 'with', 'good', 'intentions'], tags=['rt-7']),\n",
       " TaggedDocument(words=['steers', 'turns', 'in', 'a', 'snappy', 'screenplay', 'that', 'curls', 'at', 'the', 'edges', 'i', 'so', 'clever', 'you', 'want', 'to', 'hate', 'it', 'but', 'he', 'somehow', 'pulls', 'it', 'off'], tags=['rt-8']),\n",
       " TaggedDocument(words=['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slice', 'of', 'asian', 'cinema'], tags=['rt-9'])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class PermuteSentences(object):\n",
    "    def __init__(self, sents):\n",
    "        self.sents = sents\n",
    "        \n",
    "    def __iter__(self):\n",
    "        shuffled = list(self.sents)\n",
    "        random.shuffle(shuffled)\n",
    "        for sent in shuffled:\n",
    "            yield sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 11:07:51,940 : INFO : collecting all words and their counts\n",
      "2023-03-22 11:07:51,953 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2023-03-22 11:07:52,050 : INFO : PROGRESS: at example #10000, processed 188783 words (2029702/s), 17851 word types, 10000 tags\n",
      "2023-03-22 11:07:52,126 : INFO : collected 18345 word types and 10605 unique tags from a corpus of 10605 examples and 200336 words\n",
      "2023-03-22 11:07:52,126 : INFO : Creating a fresh vocabulary\n",
      "2023-03-22 11:07:52,169 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4581 unique words (24.971381847914962%% of original 18345, drops 13764)', 'datetime': '2023-03-22T11:07:52.169730', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'prepare_vocab'}\n",
      "2023-03-22 11:07:52,176 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 177523 word corpus (88.61263078028911%% of original 200336, drops 22813)', 'datetime': '2023-03-22T11:07:52.169730', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'prepare_vocab'}\n",
      "2023-03-22 11:07:52,219 : INFO : deleting the raw counts dictionary of 18345 items\n",
      "2023-03-22 11:07:52,219 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2023-03-22 11:07:52,219 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 130201.95335228511 word corpus (73.3%% of prior 177523)', 'datetime': '2023-03-22T11:07:52.219734', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'prepare_vocab'}\n",
      "2023-03-22 11:07:52,219 : INFO : constructing a huffman tree from 4581 words\n",
      "2023-03-22 11:07:52,384 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-03-22 11:07:52,457 : INFO : estimated required memory for 4581 words and 50 dimensions: 10197300 bytes\n",
      "2023-03-22 11:07:52,457 : INFO : resetting layer weights\n",
      "2023-03-22 11:07:52,476 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 4581 vocabulary and 50 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-03-22T11:07:52.476453', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'train'}\n",
      "2023-03-22 11:07:53,369 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:53,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:53,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:53,452 : INFO : EPOCH - 1 : training on 200336 raw words (140852 effective words) took 0.9s, 153344 effective words/s\n",
      "2023-03-22 11:07:54,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:54,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:54,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:54,445 : INFO : EPOCH - 2 : training on 200336 raw words (140608 effective words) took 1.0s, 142181 effective words/s\n",
      "2023-03-22 11:07:55,369 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:55,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:55,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:55,440 : INFO : EPOCH - 3 : training on 200336 raw words (140764 effective words) took 1.0s, 144468 effective words/s\n",
      "2023-03-22 11:07:56,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:56,342 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:56,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:56,342 : INFO : EPOCH - 4 : training on 200336 raw words (140830 effective words) took 0.9s, 159330 effective words/s\n",
      "2023-03-22 11:07:57,273 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:57,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:57,330 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:57,330 : INFO : EPOCH - 5 : training on 200336 raw words (140709 effective words) took 1.0s, 145514 effective words/s\n",
      "2023-03-22 11:07:58,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:58,323 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:58,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:58,323 : INFO : EPOCH - 6 : training on 200336 raw words (140762 effective words) took 1.0s, 142221 effective words/s\n",
      "2023-03-22 11:07:59,111 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:07:59,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:07:59,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:07:59,192 : INFO : EPOCH - 7 : training on 200336 raw words (140822 effective words) took 0.9s, 164832 effective words/s\n",
      "2023-03-22 11:08:00,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:08:00,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:08:00,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:08:00,170 : INFO : EPOCH - 8 : training on 200336 raw words (140684 effective words) took 1.0s, 144347 effective words/s\n",
      "2023-03-22 11:08:01,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:08:01,164 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:08:01,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:08:01,179 : INFO : EPOCH - 9 : training on 200336 raw words (140890 effective words) took 1.0s, 141888 effective words/s\n",
      "2023-03-22 11:08:02,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-03-22 11:08:02,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-03-22 11:08:02,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-03-22 11:08:02,095 : INFO : EPOCH - 10 : training on 200336 raw words (140996 effective words) took 0.9s, 157694 effective words/s\n",
      "2023-03-22 11:08:02,095 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2003360 raw words (1407917 effective words) took 9.6s, 146448 effective words/s', 'datetime': '2023-03-22T11:08:02.095768', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'train'}\n",
      "2023-03-22 11:08:02,095 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dbow,d50,n5,hs,mc5,s0.001,t3)', 'datetime': '2023-03-22T11:08:02.095768', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.25309-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "permuter = PermuteSentences(unsup_sentences) \n",
    "model = Doc2Vec(permuter, dm=0, hs=1, vector_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done with training, free up some memory\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 11:12:46,964 : INFO : loading Doc2Vec object from reviews.d2v\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reviews.d2v'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11552\\1629015846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2vec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reviews.d2v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# in other program, we could write: model = Doc2Vec.load('reviews.d2v')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m         \"\"\"\n\u001b[0;32m    806\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrethrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m             logger.error(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1928\u001b[0m         \"\"\"\n\u001b[0;32m   1929\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1930\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1931\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1932\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \"\"\"\n\u001b[1;32m-> 1459\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reviews.d2v'"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec.load('reviews.d2v')\n",
    "# in other program, we could write: model = Doc2Vec.load('reviews.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11552\\2718558519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This place is not worth your time, let alone Vegas.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.infer_vector(extract_words(\"This place is not worth your time, let alone Vegas.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(\n",
    "    [model.infer_vector(extract_words(\"This place is not worth your time, let alone Vegas.\"))],\n",
    "    [model.infer_vector(extract_words(\"Service sucks.\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    [model.infer_vector(extract_words(\"Highly recommended.\"))],\n",
    "    [model.infer_vector(extract_words(\"Service sucks.\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentvecs = []\n",
    "sentiments = []\n",
    "for fname in [\"yelp\", \"amazon_cells\", \"imdb\"]: \n",
    "    with open(\"sentiment labelled sentences/%s_labelled.txt\" % fname, encoding='UTF-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            line_split = line.strip().split('\\t')\n",
    "            sentences.append(line_split[0])\n",
    "            words = extract_words(line_split[0])\n",
    "            sentvecs.append(model.infer_vector(words, steps=10)) # create a vector for this document\n",
    "            sentiments.append(int(line_split[1]))\n",
    "            \n",
    "# shuffle sentences, sentvecs, sentiments together\n",
    "combined = list(zip(sentences, sentvecs, sentiments))\n",
    "random.shuffle(combined)\n",
    "sentences, sentvecs, sentiments = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=9)\n",
    "clfrf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, sentvecs, sentiments, cv=5)\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clfrf, sentvecs, sentiments, cv=5)\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag-of-words comparison\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, sentences, sentiments, cv=5)\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
